# Sign Language Detection
This project focuses on building a computer vision model for detecting American Sign Language (ASL). The goal was to achieve high accuracy in real-time sign language detection to aid communication for individuals with hearing impairments. The project utilized TensorFlow as the deep learning framework, in conjunction with OpenCV and MediaPipe computer vision techniques, to enhance an existing GitHub repository.

### Key Achievements

- Accuracy Improvement: Accomplished remarkable accuracy improvement from 85% to an exceptional 99% for American Sign Language detection. This significant enhancement was achieved by leveraging TensorFlow's capabilities as a powerful deep learning framework. Through careful model architecture design, optimization, and training on a large dataset, we were able to achieve highly accurate predictions.

- Real-Time Letter Detection: Implemented a novel Convolutional Neural Network (CNN) architecture to improve the real-time letter detection performance within a live setting. By customizing the CNN layers, tuning hyperparameters, and utilizing advanced techniques like data augmentation, we enhanced the model's accuracy and efficiency, ensuring prompt and reliable detection of sign language gestures.

- Computer Vision Techniques: Incorporated OpenCV and MediaPipe computer vision techniques to maximize the effectiveness of the system. OpenCV was used for image preprocessing, such as resizing, cropping, and normalization, to ensure consistent input data for the model. MediaPipe, on the other hand, provided valuable functionalities for hand tracking and pose estimation, which further improved the accuracy and robustness of the sign language detection.

### How to use this Model:

Just Run `live-asl-detection.py`


### Future Enhancements
The sign language detection project has great potential for further improvements and extensions:

- Multi-Language Support: Extend the model to detect and interpret sign language gestures from different languages, enabling effective communication across various cultural contexts.

- Gesture Recognition: Expand the model to recognize and classify complex sign language phrases and sentences, enabling more comprehensive communication capabilities.

- User Interface Development: Build an intuitive and user-friendly interface that facilitates real-time sign language detection and communication, making it accessible to a broader user base.

### Conclusion
This project showcases the successful application of computer vision and deep learning techniques for sign language detection. By utilizing TensorFlow as the deep learning framework and incorporating OpenCV and MediaPipe for computer vision enhancements, we achieved exceptional accuracy in real-time sign language gesture detection. The project has the potential to positively impact the lives of individuals with hearing impairments, providing them with an efficient means of communication over time.

### References
- TensorFlow
- OpenCV
- MediaPipe
